{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.tokenformer import TokenformerLayer\n",
    "from training.train import train_with_scaling_ver2,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Device Count: 1\n",
      "CUDA Device Name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
    "print(\"CUDA Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TokenFormer with scalling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va train ces diffÃ©rentes configuration : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š ModÃ¨le : {'hidden_dim': 32, 'num_heads': 1, 'max_seq_len': 32, 'token_num': 2, 'vocab_size': 10656}\n",
      "ðŸ”¹ PyTorch Trainable Params : 694_304\n",
      "\n",
      "ðŸ“Š ModÃ¨le : {'hidden_dim': 32, 'num_heads': 1, 'max_seq_len': 32, 'token_num': 4, 'vocab_size': 10656}\n",
      "ðŸ”¹ PyTorch Trainable Params : 694_944\n",
      "\n",
      "ðŸ“Š ModÃ¨le : {'hidden_dim': 32, 'num_heads': 1, 'max_seq_len': 32, 'token_num': 8, 'vocab_size': 10656}\n",
      "ðŸ”¹ PyTorch Trainable Params : 696_224\n",
      "\n",
      "ðŸ“Š ModÃ¨le : {'hidden_dim': 32, 'num_heads': 1, 'max_seq_len': 32, 'token_num': 16, 'vocab_size': 10656}\n",
      "ðŸ”¹ PyTorch Trainable Params : 698_784\n",
      "\n",
      "ðŸ“Š ModÃ¨le : {'hidden_dim': 32, 'num_heads': 1, 'num_layers': 12, 'max_seq_len': 32, 'token_num': 32, 'vocab_size': 10656}\n",
      "ðŸ”¹ PyTorch Trainable Params : 703_904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_configs = [\n",
    "    {\n",
    "        \"hidden_dim\": 32,  \n",
    "        \"num_heads\": 1,        \n",
    "        \"max_seq_len\": 32,   \n",
    "        \"token_num\": 2,     \n",
    "        \"vocab_size\": 10656  \n",
    "    },\n",
    "    {\n",
    "        \"hidden_dim\": 32,\n",
    "        \"num_heads\": 1,\n",
    "        \"max_seq_len\": 32,\n",
    "        \"token_num\": 4,  # 4x plus de tokens paramÃ©triques\n",
    "        \"vocab_size\": 10656\n",
    "    },\n",
    "    {\n",
    "        \"hidden_dim\": 32,\n",
    "        \"num_heads\": 1,\n",
    "        \"max_seq_len\": 32,\n",
    "        \"token_num\": 8,  # 8x plus de tokens paramÃ©triques\n",
    "        \"vocab_size\": 10656\n",
    "    },\n",
    "    {\n",
    "        \"hidden_dim\": 32,\n",
    "        \"num_heads\": 1,\n",
    "        \"max_seq_len\": 32,\n",
    "        \"token_num\": 16,  # 16x plus de tokens paramÃ©triques\n",
    "        \"vocab_size\": 10656\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"hidden_dim\": 32,\n",
    "        \"num_heads\": 1,\n",
    "        \"num_layers\": 12,\n",
    "        \"max_seq_len\": 32,\n",
    "        \"token_num\": 32,  # 16x plus de tokens paramÃ©triques\n",
    "        \"vocab_size\": 10656\n",
    "    }\n",
    "]\n",
    "\n",
    "# Tester chaque configuration\n",
    "for config in model_configs:\n",
    "    model = TokenformerLayer(\n",
    "        hidden_size=config[\"hidden_dim\"],\n",
    "        vocab_size=config[\"vocab_size\"],\n",
    "        num_attention_heads=config[\"num_heads\"],\n",
    "        max_seq_len=config[\"max_seq_len\"],\n",
    "        token_num=config[\"token_num\"]\n",
    "    )\n",
    "\n",
    "    trainable_params_auto = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(f\"ðŸ“Š ModÃ¨le : {config}\")\n",
    "\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     print(f\"{name}: {param.numel():_} paramÃ¨tres\")\n",
    "\n",
    "    print(f\"ðŸ”¹ PyTorch Trainable Params : {trainable_params_auto:_}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 | Epoch 1 | Train Loss: 12.5833 | Val Loss: 12.0479 | Test Loss: 12.0457 | Epoch Time: 41.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 | Epoch 2 | Train Loss: 11.1020 | Val Loss: 9.9436 | Test Loss: 9.9363 | Epoch Time: 42.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 | Epoch 3 | Train Loss: 8.6607 | Val Loss: 7.5484 | Test Loss: 7.5314 | Epoch Time: 44.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 | Epoch 4 | Train Loss: 7.0608 | Val Loss: 6.7724 | Test Loss: 6.7459 | Epoch Time: 41.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 | Epoch 5 | Train Loss: 6.6787 | Val Loss: 6.6289 | Test Loss: 6.5988 | Epoch Time: 43.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 | Epoch 6 | Train Loss: 6.6038 | Val Loss: 6.5973 | Test Loss: 6.5665 | Epoch Time: 44.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 | Epoch 7 | Train Loss: 6.5812 | Val Loss: 6.5823 | Test Loss: 6.5536 | Epoch Time: 44.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 | Epoch 8 | Train Loss: 6.5690 | Val Loss: 6.5740 | Test Loss: 6.5448 | Epoch Time: 42.70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 | Epoch 9 | Train Loss: 6.5613 | Val Loss: 6.5692 | Test Loss: 6.5399 | Epoch Time: 41.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 | Epoch 10 | Train Loss: 6.5566 | Val Loss: 6.5643 | Test Loss: 6.5356 | Epoch Time: 41.19s\n",
      "âœ… TokenFormer scalÃ© Ã  4 tokens.\n",
      "ðŸ”¼ Scaling step 1: token_num = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Epoch 1 | Train Loss: 6.7736 | Val Loss: 6.6868 | Test Loss: 6.6609 | Epoch Time: 41.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Epoch 2 | Train Loss: 6.6467 | Val Loss: 6.6286 | Test Loss: 6.6005 | Epoch Time: 41.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Epoch 3 | Train Loss: 6.6097 | Val Loss: 6.6063 | Test Loss: 6.5770 | Epoch Time: 42.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Epoch 4 | Train Loss: 6.5916 | Val Loss: 6.5937 | Test Loss: 6.5647 | Epoch Time: 42.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Epoch 5 | Train Loss: 6.5796 | Val Loss: 6.5851 | Test Loss: 6.5561 | Epoch Time: 37.32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Epoch 6 | Train Loss: 6.5712 | Val Loss: 6.5792 | Test Loss: 6.5500 | Epoch Time: 37.95s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Epoch 7 | Train Loss: 6.5657 | Val Loss: 6.5744 | Test Loss: 6.5452 | Epoch Time: 38.08s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Epoch 8 | Train Loss: 6.5608 | Val Loss: 6.5710 | Test Loss: 6.5415 | Epoch Time: 38.73s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Epoch 9 | Train Loss: 6.5568 | Val Loss: 6.5681 | Test Loss: 6.5391 | Epoch Time: 39.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 | Epoch 10 | Train Loss: 6.5541 | Val Loss: 6.5658 | Test Loss: 6.5364 | Epoch Time: 46.30s\n",
      "âœ… TokenFormer scalÃ© Ã  8 tokens.\n",
      "ðŸ”¼ Scaling step 2: token_num = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 | Epoch 1 | Train Loss: 7.9353 | Val Loss: 7.5958 | Test Loss: 7.5784 | Epoch Time: 44.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 | Epoch 2 | Train Loss: 7.3666 | Val Loss: 7.1868 | Test Loss: 7.1662 | Epoch Time: 44.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 | Epoch 3 | Train Loss: 7.0557 | Val Loss: 6.9571 | Test Loss: 6.9338 | Epoch Time: 39.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 | Epoch 4 | Train Loss: 6.8778 | Val Loss: 6.8238 | Test Loss: 6.7984 | Epoch Time: 38.80s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 | Epoch 5 | Train Loss: 6.7724 | Val Loss: 6.7451 | Test Loss: 6.7182 | Epoch Time: 37.80s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 | Epoch 6 | Train Loss: 6.7099 | Val Loss: 6.6976 | Test Loss: 6.6703 | Epoch Time: 41.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 | Epoch 7 | Train Loss: 6.6712 | Val Loss: 6.6677 | Test Loss: 6.6395 | Epoch Time: 39.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 | Epoch 8 | Train Loss: 6.6457 | Val Loss: 6.6469 | Test Loss: 6.6186 | Epoch Time: 39.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 | Epoch 9 | Train Loss: 6.6269 | Val Loss: 6.6322 | Test Loss: 6.6035 | Epoch Time: 40.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 | Epoch 10 | Train Loss: 6.6133 | Val Loss: 6.6209 | Test Loss: 6.5919 | Epoch Time: 39.74s\n",
      "âœ… TokenFormer scalÃ© Ã  16 tokens.\n",
      "ðŸ”¼ Scaling step 3: token_num = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 | Epoch 1 | Train Loss: 9.2801 | Val Loss: 9.0722 | Test Loss: 9.0593 | Epoch Time: 40.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 | Epoch 2 | Train Loss: 8.8859 | Val Loss: 8.7299 | Test Loss: 8.7159 | Epoch Time: 39.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 | Epoch 3 | Train Loss: 8.5758 | Val Loss: 8.4492 | Test Loss: 8.4341 | Epoch Time: 38.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 | Epoch 4 | Train Loss: 8.3162 | Val Loss: 8.2104 | Test Loss: 8.1944 | Epoch Time: 39.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 | Epoch 5 | Train Loss: 8.0937 | Val Loss: 8.0043 | Test Loss: 7.9873 | Epoch Time: 40.94s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 | Epoch 6 | Train Loss: 7.9003 | Val Loss: 7.8250 | Test Loss: 7.8071 | Epoch Time: 43.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 | Epoch 7 | Train Loss: 7.7321 | Val Loss: 7.6685 | Test Loss: 7.6498 | Epoch Time: 45.93s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 | Epoch 8 | Train Loss: 7.5850 | Val Loss: 7.5318 | Test Loss: 7.5122 | Epoch Time: 40.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 | Epoch 9 | Train Loss: 7.4565 | Val Loss: 7.4125 | Test Loss: 7.3921 | Epoch Time: 40.84s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 | Epoch 10 | Train Loss: 7.3439 | Val Loss: 7.3083 | Test Loss: 7.2871 | Epoch Time: 41.23s\n",
      "âœ… TokenFormer scalÃ© Ã  32 tokens.\n",
      "ðŸ”¼ Scaling step 4: token_num = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Epoch 1 | Train Loss: 7.9488 | Val Loss: 7.8814 | Test Loss: 7.8632 | Epoch Time: 41.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Epoch 2 | Train Loss: 7.7931 | Val Loss: 7.7359 | Test Loss: 7.7171 | Epoch Time: 41.70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Epoch 3 | Train Loss: 7.6607 | Val Loss: 7.6074 | Test Loss: 7.5879 | Epoch Time: 40.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Epoch 4 | Train Loss: 7.5343 | Val Loss: 7.4941 | Test Loss: 7.4739 | Epoch Time: 39.93s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Epoch 5 | Train Loss: 7.4270 | Val Loss: 7.3937 | Test Loss: 7.3731 | Epoch Time: 41.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Epoch 6 | Train Loss: 7.3320 | Val Loss: 7.3050 | Test Loss: 7.2836 | Epoch Time: 42.45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Epoch 7 | Train Loss: 7.2552 | Val Loss: 7.2264 | Test Loss: 7.2044 | Epoch Time: 44.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Epoch 8 | Train Loss: 7.1760 | Val Loss: 7.1568 | Test Loss: 7.1343 | Epoch Time: 41.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Epoch 9 | Train Loss: 7.1074 | Val Loss: 7.0951 | Test Loss: 7.0719 | Epoch Time: 43.33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 | Epoch 10 | Train Loss: 7.0488 | Val Loss: 7.0404 | Test Loss: 7.0167 | Epoch Time: 46.20s\n",
      "Final results saved in: scaling_results_2.csv\n"
     ]
    }
   ],
   "source": [
    "token_num_init = 2\n",
    "\n",
    "train_with_scaling_ver2(\n",
    "    initial_token_num=token_num_init,\n",
    "    scaling_steps=4, \n",
    "    new_tokens_per_step=[2, 4, 8, 16, 32],  \n",
    "    hidden_dim=32,\n",
    "    num_heads=1,\n",
    "    max_seq_len=32,\n",
    "    batch_size=32,\n",
    "    num_epochs=10,\n",
    "    learning_rate=0.001,\n",
    "    val_ratio=0.1,\n",
    "    test_ratio=0.1,\n",
    "    model_base_name=\"tokenformer_scaled_3_2\",\n",
    "    results_file_name=\"scaling_results_2.csv\",\n",
    "    subset_size=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Vocab Size: 10656\n",
      "Model Type: Transformer\n",
      "Trainable Parameters: 896_928\n",
      "Approximate Computational Cost (FLOPS): 16_777_216\n",
      "Training Samples: 53524, Validation Samples: 17841, Test Samples: 17841\n",
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 5.8653 | Val Loss: 4.7655 | Val Perplexity: 117.3890 | Time: 60.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 3.0524 | Val Loss: 0.6965 | Val Perplexity: 2.0067 | Time: 59.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 0.4824 | Val Loss: 0.2150 | Val Perplexity: 1.2398 | Time: 61.33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Train Loss: 0.2586 | Val Loss: 0.1902 | Val Perplexity: 1.2095 | Time: 60.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 0.2202 | Val Loss: 0.1827 | Val Perplexity: 1.2004 | Time: 60.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Train Loss: 0.2028 | Val Loss: 0.1820 | Val Perplexity: 1.1996 | Time: 58.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | Train Loss: 0.1918 | Val Loss: 0.1785 | Val Perplexity: 1.1954 | Time: 59.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Train Loss: 0.1828 | Val Loss: 0.1772 | Val Perplexity: 1.1939 | Time: 59.45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Train Loss: 0.1775 | Val Loss: 0.1763 | Val Perplexity: 1.1927 | Time: 59.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Train Loss: 0.1723 | Val Loss: 0.1774 | Val Perplexity: 1.1941 | Time: 60.64s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | Train Loss: 0.1679 | Val Loss: 0.1759 | Val Perplexity: 1.1924 | Time: 59.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | Train Loss: 0.1639 | Val Loss: 0.1760 | Val Perplexity: 1.1925 | Time: 59.48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | Train Loss: 0.1603 | Val Loss: 0.1773 | Val Perplexity: 1.1940 | Time: 59.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Lancer l'entraÃ®nement\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_tokenformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_checkpoint_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtransformer_ver2_openwebdataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_results_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtransformer_ver2_openwebdataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m\\\\wsl.localhost\\Ubuntu\\home\\hocine\\GitHub\\TokenFormer-Reimplementation\\tokenformer\\training\\train.py:138\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(file_path, use_tokenformer, hidden_dim, num_heads, num_layers, max_seq_len, batch_size, num_epochs, learning_rate, token_num, val_ratio, test_ratio, model_checkpoint_file_name, model_results_file_name)\u001b[0m\n\u001b[0;32m    135\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    137\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_batch)\n\u001b[1;32m--> 138\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    140\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\Kadem\\.pyenv\\pyenv-win\\versions\\3.9.9\\lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kadem\\.pyenv\\pyenv-win\\versions\\3.9.9\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kadem\\.pyenv\\pyenv-win\\versions\\3.9.9\\lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    824\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    825\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lancer l'entraÃ®nement\n",
    "train(\n",
    "    use_tokenformer=False,\n",
    "    hidden_dim=32,\n",
    "    num_heads=4,\n",
    "    num_layers=16,\n",
    "    max_seq_len=32,\n",
    "    batch_size=32,\n",
    "    num_epochs=50,\n",
    "    learning_rate=0.001,\n",
    "    token_num=32,\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.2,\n",
    "    model_checkpoint_file_name='transformer_ver2_openwebdataset',\n",
    "    model_results_file_name='transformer_ver2_openwebdataset'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
