{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input tokens in training data: 458319\n",
      "Initial model parameters: 1.02 M parameters\n",
      "Iter 0: Loss 4.4805, Perplexity 88.2766, Param Tokens per Head 128, Total Training Tokens 2048, Cumulative Time 3.61 sec\n",
      "Iter 500: Loss 2.4140, Perplexity 11.1788, Param Tokens per Head 128, Total Training Tokens 1026048, Cumulative Time 56.15 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 322\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mprint\u001b[39m(decode(generated))\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 300\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    298\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    299\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 300\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m total_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m global_start_time\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTotal training time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/optim/adamw.py:171\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    158\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    161\u001b[0m         group,\n\u001b[1;32m    162\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m         state_steps,\n\u001b[1;32m    169\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/optim/adamw.py:321\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 321\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/optim/adamw.py:440\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    438\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "\n",
    "# ---------------------------\n",
    "# Hyperparameters\n",
    "# ---------------------------\n",
    "BATCH_SIZE = 32         # Number of sequences per batch\n",
    "BLOCK_SIZE = 64         # Maximum context length\n",
    "MAX_ITERS = 5000        # Total number of training iterations\n",
    "EVAL_INTERVAL = 500     # Evaluation interval (in iterations)\n",
    "LEARNING_RATE = 1e-3    # Learning rate\n",
    "N_EMBD = 128            # Embedding dimension\n",
    "N_HEAD = 4              # Number of attention heads\n",
    "N_LAYER = 6             # Number of Transformer layers\n",
    "DROPOUT = 0             # Dropout rate\n",
    "\n",
    "# Initial number of parameter tokens per attention head (for Pattention)\n",
    "INIT_PARAM_TOKENS = 128\n",
    "\n",
    "# Progressive scaling schedule:\n",
    "# At specified iteration numbers, expand the number of parameter tokens.\n",
    "SCALING_SCHEDULE = {1000: 512, 2000: 1024, 3000: 2048, 4000: 5096}\n",
    "\n",
    "# ---------------------------\n",
    "# Device Selection\n",
    "# ---------------------------\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "EVAL_ITERS = 200\n",
    "\n",
    "# Global training start time (used for timing logs)\n",
    "global_start_time = time.time()\n",
    "\n",
    "##########################\n",
    "# TokenFormer Pattention Modules\n",
    "##########################\n",
    "\n",
    "class TokenFormerHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A Pattention head that uses learnable parameter tokens to compute keys and values.\n",
    "    - Query: computed from the input tokens.\n",
    "    - Keys and Values: computed from a set of learnable parameter tokens.\n",
    "    \"\"\"\n",
    "    def __init__(self, head_size, num_param_tokens):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(N_EMBD, head_size, bias=True)\n",
    "        # Learnable parameter tokens for keys and values\n",
    "        self.KP = nn.Parameter(torch.randn(num_param_tokens, head_size))\n",
    "        self.VP = nn.Parameter(torch.randn(num_param_tokens, head_size))\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "        self.scale = head_size ** -0.5\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, N_EMBD)\n",
    "        B, T, _ = x.shape\n",
    "        q = self.query(x)  # (B, T, head_size)\n",
    "        attn_scores = q @ self.KP.T * self.scale  # (B, T, num_param_tokens)\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        out = attn_weights @ self.VP  # (B, T, head_size)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head attention module based on Pattention.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_heads, head_size, num_param_tokens):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([\n",
    "            TokenFormerHead(head_size, num_param_tokens) for _ in range(num_heads)\n",
    "        ])\n",
    "        self.proj = nn.Linear(head_size * num_heads, N_EMBD)\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        head_outputs = [head(x) for head in self.heads]\n",
    "        concatenated = torch.cat(head_outputs, dim=-1)\n",
    "        out = self.dropout(self.proj(concatenated))\n",
    "        return out\n",
    "\n",
    "##########################\n",
    "# Pattention-based Feed-Forward Module\n",
    "##########################\n",
    "\n",
    "class PattentionFFN(nn.Module):\n",
    "    \"\"\"\n",
    "    A feed-forward module based on Pattention.\n",
    "    It replaces the traditional MLP with two consecutive Pattention layers.\n",
    "    A LayerNorm is applied at the beginning, and a residual connection is added.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_embd, num_param_tokens):\n",
    "        super().__init__()\n",
    "        self.ln = nn.LayerNorm(n_embd)\n",
    "        # Using two consecutive Pattention layers (each implemented as a TokenFormerHead)\n",
    "        # Here, we set the output dimension equal to n_embd so that no additional projection is required.\n",
    "        self.pattn1 = TokenFormerHead(n_embd, num_param_tokens)\n",
    "        self.pattn2 = TokenFormerHead(n_embd, num_param_tokens)\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.ln(x)\n",
    "        x = self.pattn1(x)\n",
    "        x = self.pattn2(x)\n",
    "        x = self.dropout(x)\n",
    "        return residual + x\n",
    "\n",
    "##########################\n",
    "# Other Module Definitions\n",
    "##########################\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    A Transformer block consisting of:\n",
    "      - A multi-head attention layer (based on Pattention)\n",
    "      - A feed-forward network (using Pattention-based FFN)\n",
    "    Both sub-layers use residual connections.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size, INIT_PARAM_TOKENS)\n",
    "        # Replace traditional FFN with our PattentionFFN module\n",
    "        self.ffwd = PattentionFFN(n_embd, INIT_PARAM_TOKENS)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        # Note: the feed-forward block (PattentionFFN) already includes normalization, so no separate ln2 here.\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(x)\n",
    "        return x\n",
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A GPT-style language model.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, N_EMBD)\n",
    "        self.position_embedding_table = nn.Embedding(BLOCK_SIZE, N_EMBD)\n",
    "        self.blocks = nn.Sequential(*[Block(N_EMBD, n_head=N_HEAD) for _ in range(N_LAYER)])\n",
    "        self.ln_f = nn.LayerNorm(N_EMBD)\n",
    "        self.lm_head = nn.Linear(N_EMBD, vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -BLOCK_SIZE:]\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "##########################\n",
    "# Progressive Scaling\n",
    "##########################\n",
    "\n",
    "def progressive_scale_model(model, new_num_param_tokens):\n",
    "    \"\"\"\n",
    "    Expand the parameter tokens (used in Pattention) in all TokenFormerHead modules.\n",
    "    The new tokens are zero-initialized.\n",
    "    \"\"\"\n",
    "    for block in model.blocks:\n",
    "        for head in block.sa.heads:\n",
    "            old_KP, old_VP = head.KP, head.VP\n",
    "            old_num = old_KP.shape[0]\n",
    "            if new_num_param_tokens <= old_num:\n",
    "                continue\n",
    "            head_size = old_KP.shape[1]\n",
    "            extra_KP = torch.zeros(new_num_param_tokens - old_num, head_size, device=old_KP.device)\n",
    "            extra_VP = torch.zeros(new_num_param_tokens - old_num, head_size, device=old_VP.device)\n",
    "            head.KP = nn.Parameter(torch.cat([old_KP, extra_KP], dim=0))\n",
    "            head.VP = nn.Parameter(torch.cat([old_VP, extra_VP], dim=0))\n",
    "    \n",
    "    elapsed_total = time.time() - global_start_time\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"\\n========== Scaling Event ==========\")\n",
    "    print(f\"Cumulative training time: {elapsed_total:.2f} seconds\")\n",
    "    print(f\"Parameter tokens per head expanded to: {new_num_param_tokens}\")\n",
    "    print(f\"Total model parameters now: {total_params/1e6:.2f} M\")\n",
    "    print(\"===================================\\n\")\n",
    "    return model\n",
    "\n",
    "##########################\n",
    "# Data Loading and Preprocessing\n",
    "##########################\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    chars = sorted(list(set(text)))\n",
    "    stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "    itos = {i: ch for i, ch in enumerate(chars)}\n",
    "    encode = lambda s: [stoi[c] for c in s]\n",
    "    decode = lambda l: ''.join([itos[i] for i in l])\n",
    "    data = torch.tensor(encode(text), dtype=torch.long)\n",
    "    return data, stoi, itos, decode\n",
    "\n",
    "def create_data_splits(data, train_ratio=0.9):\n",
    "    n = int(train_ratio * len(data))\n",
    "    return data[:n], data[n:]\n",
    "\n",
    "def get_batch(data, block_size, batch_size):\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x.to(device), y.to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, data, block_size, eval_iters):\n",
    "    model.eval()\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    for k in range(eval_iters):\n",
    "        xb, yb = get_batch(data, block_size, BATCH_SIZE)\n",
    "        _, loss = model(xb, yb)\n",
    "        losses[k] = loss.item()\n",
    "    avg_loss = losses.mean().item()\n",
    "    model.train()\n",
    "    return avg_loss, math.exp(avg_loss)\n",
    "\n",
    "##########################\n",
    "# Main Training Function\n",
    "##########################\n",
    "\n",
    "def train_model():\n",
    "    # Load data and create splits\n",
    "    data, stoi, itos, decode = load_data('pokemon.txt')\n",
    "    vocab_size = len(stoi)\n",
    "    train_data, val_data = create_data_splits(data)\n",
    "    total_input_tokens = len(train_data)\n",
    "    print(f\"Total input tokens in training data: {total_input_tokens}\")\n",
    "\n",
    "    # Initialize model\n",
    "    model = GPTLanguageModel(vocab_size).to(device)\n",
    "    print(f\"Initial model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f} M parameters\")\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    total_training_tokens = 0\n",
    "    logs = []\n",
    "    current_param_tokens = INIT_PARAM_TOKENS\n",
    "\n",
    "    # Progressive scaling schedule is defined in SCALING_SCHEDULE\n",
    "    global global_start_time\n",
    "    global_start_time = time.time()\n",
    "\n",
    "    for iter in range(MAX_ITERS):\n",
    "        # Check if a scaling event is scheduled\n",
    "        if iter in SCALING_SCHEDULE:\n",
    "            new_token_count = SCALING_SCHEDULE[iter]\n",
    "            model = progressive_scale_model(model, new_token_count)\n",
    "            current_param_tokens = new_token_count\n",
    "\n",
    "        xb, yb = get_batch(train_data, BLOCK_SIZE, BATCH_SIZE)\n",
    "        total_training_tokens += xb.shape[0] * xb.shape[1]\n",
    "\n",
    "        if iter % EVAL_INTERVAL == 0 or iter == MAX_ITERS - 1:\n",
    "            loss_val, ppl_val = evaluate_model(model, train_data, BLOCK_SIZE, EVAL_ITERS)\n",
    "            elapsed = time.time() - global_start_time\n",
    "            log_line = [iter, loss_val, ppl_val, current_param_tokens, total_training_tokens]\n",
    "            logs.append(log_line)\n",
    "            print(f\"Iter {iter}: Loss {loss_val:.4f}, Perplexity {ppl_val:.4f}, \"\n",
    "                  f\"Param Tokens per Head {current_param_tokens}, Total Training Tokens {total_training_tokens}, \"\n",
    "                  f\"Cumulative Time {elapsed:.2f} sec\")\n",
    "        \n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    total_time = time.time() - global_start_time\n",
    "    print(f\"\\nTotal training time: {total_time:.2f} seconds.\")\n",
    "    print(f\"Total training tokens processed: {total_training_tokens}\")\n",
    "\n",
    "    # Save logs to CSV\n",
    "    csv_filename = \"training_log.csv\"\n",
    "    with open(csv_filename, mode=\"w\", newline=\"\") as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow([\"iteration\", \"loss\", \"perplexity\", \"param_tokens\", \"total_training_tokens\"])\n",
    "        for log in logs:\n",
    "            csv_writer.writerow(log)\n",
    "    print(f\"Training log saved to {csv_filename}\")\n",
    "\n",
    "    # Generate sample text\n",
    "    context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "    generated = model.generate(context, max_new_tokens=500)[0].tolist()\n",
    "    print(\"\\nGenerated Text:\")\n",
    "    print(decode(generated))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#  CSV \n",
    "df = pd.read_csv(\"training_log.csv\")\n",
    "\n",
    "# \n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(df[\"iteration\"], df[\"perplexity\"], marker=\"o\", linestyle=\"-\", color=\"b\", label=\"Perplexity\")\n",
    "\n",
    "# \n",
    "plt.title(\"Training Perplexity over Iterations\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
